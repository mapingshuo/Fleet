grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 08:52:32.353966 96910 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 08:53:37.777923 97278 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 08:55:25.099876 97660 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 08:56:52.565814 97888 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 09:01:03.719364 98158 init.cc:67] Init commandline: dummy /usr/local/lib/python2.7/dist-packages/paddle/distributed/launch.py --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,enable_inplace_whitelist,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 09:06:38.284891   243 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 09:11:05.153221  1073 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 09:15:01.151118  1360 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:27:01.911515 35534 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:28:34.080122 36020 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 224, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 220, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 213, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:29:42.742115 36237 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 224, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 220, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 213, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:30:01.613807 36449 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 224, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 220, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 213, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:34:48.015044 36813 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 224, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 220, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 213, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:37:33.370981 37313 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 224, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 220, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 213, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:40:08.778225 37561 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 224, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 220, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 213, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0806 11:40:39.887797 37790 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 224, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 220, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 213, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
/usr/bin/python: No module named paddle.distributed
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:07:06.654884   284 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:07:59.069979   530 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:08:54.256669   705 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:09:44.722216   857 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:10:21.424226  1009 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:13:05.861189  1229 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:14:05.498548  1442 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:14:53.172430  1733 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:15:23.450237  1957 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:15:44.496845  2173 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:16:18.691447  2401 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:16:47.605667  2623 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:34:56.607349  3048 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:36:18.855942  3312 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:37:27.699856  3479 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:40:40.321751  3705 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:41:00.716439  3853 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:41:39.953025  4054 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:43:02.615547  4221 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:44:17.072186  4361 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:44:32.962697  4505 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:46:04.213682  4852 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:48:23.237383  5142 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:48:50.324932  5295 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:50:31.424178  5518 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:51:03.358984  5672 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:52:12.577823  5817 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:55:54.137274  5961 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:56:57.785069  6114 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:57:23.797461  6259 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:57:44.461277  6601 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:58:45.831346  6951 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 07:59:33.379379  7282 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:05:48.263679  8189 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:06:34.113327  8629 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:07:36.924448  9086 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:08:29.861572  9432 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:14:32.788067 10050 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:15:52.149369 10405 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:17:41.389045 10854 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:18:39.402730 11340 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:21:35.925372 11843 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:22:18.256263 12245 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:23:50.609609 12650 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:26:19.479539 13089 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:31:05.619725 13242 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '4096', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status -6
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:32:09.757591 13701 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:32:19.002626 13892 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:33:12.725044 14352 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:34:21.594485 14764 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 08:37:19.138891 15243 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '1024', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
trainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173,127.0.0.1:6174,127.0.0.1:6175,127.0.0.1:6176,127.0.0.1:6177 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 8
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 211, in start_procs
    returncode=procs[i].returncode, cmd=cmds[i])
subprocess.CalledProcessError: Command '['/usr/bin/python', '-u', './train.py', '--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '1024', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']' returned non-zero exit status 1
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 09:40:10.824137 16181 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
W0807 09:40:10.836127 16181 init.cc:129] Compiled with WITH_GPU, but no GPU found in runtime.
-----------  Configuration Arguments -----------
cluster_node_ips: 127.0.0.1
log_dir: log
node_ip: 127.0.0.1
print_config: True
selected_gpus: None
started_port: 6170
training_script: ./train.py
training_script_args: ['--use_cuda', 'true', '--weight_sharing', 'true', '--batch_size', '1024', '--data_dir', 'data/train', '--validation_set_dir', 'data/validation', '--bert_config_path', 'data/demo_config/bert_config.json', '--vocab_path', 'data/demo_config/vocab.txt', '--generate_neg_sample', 'true', '--checkpoints', './output', '--save_steps', '10000', '--learning_rate', '1e-4', '--weight_decay', '0.01', '--max_seq_len', '512', '--skip_steps', '20', '--validation_steps', '1000', '--num_iteration_per_drop_scope', '10', '--use_fp16', 'false', '--loss_scaling', '8.0']
------------------------------------------------
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 222, in <module>
    launch()
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 218, in launch
    start_procs(args)
  File "/paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py", line 146, in start_procs
    gpus_num = fluid.core.get_cuda_device_count()
paddle.fluid.core_avx.EnforceNotMet: cudaGetDeviceCount failed in paddle::platform::GetCUDADeviceCountImpl, error code : 35, Please see detail in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3f51e3575c2178246db0a94a430e0038: CUDA driver version is insufficient for CUDA runtime version at [/paddle/paddle/fluid/platform/gpu_info.cc:106]
PaddlePaddle Call Stacks: 
0       0x7fe1693225fap void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 506
1       0x7fe169323305p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 165
2       0x7fe16b689306p paddle::platform::GetCUDADeviceCount() + 934
3       0x7fe16931b0dap
4       0x7fe169356054p
5             0x4bc4aap PyEval_EvalFrameEx + 1482
6             0x4b9b66p PyEval_EvalCodeEx + 774
7             0x4c1f56p PyEval_EvalFrameEx + 24694
8             0x4b9b66p PyEval_EvalCodeEx + 774
9             0x4c1f56p PyEval_EvalFrameEx + 24694
10            0x4b9b66p PyEval_EvalCodeEx + 774
11            0x4bf7a2p PyEval_EvalFrameEx + 14530
12            0x4b9b66p PyEval_EvalCodeEx + 774
13            0x4c17c6p PyEval_EvalFrameEx + 22758
14            0x4b9b66p PyEval_EvalCodeEx + 774
15            0x4d5669p
16            0x4a587ep PyObject_Call + 62
17            0x51a866p
18            0x4939ccp Py_Main + 1612
19      0x7fe20037c830p __libc_start_main + 240
20            0x493299p _start + 41

grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 09:58:33.673863 16585 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 11:58:48.455982 17528 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0807 12:02:24.048101 17692 init.cc:68] Init commandline: dummy /paddle/build/build_ubuntu_polishfleet_debug_gpu_y_grpc/python/paddle/distributed/launch.py --tryfromenv=check_nan_inf,fast_check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,communicator_merge_sparse_grad,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,cudnn_batchnorm_spatial_persistent 
